{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "eed8075e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell contains the essential imports you will need â€“ DO NOT CHANGE THE CONTENTS! ##\n",
    "# src: MNIST_Handwritten_Digits_STARTER.ipynb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# MNIST is a default dataset: we can load from torchvision directly\n",
    "from torchvision import datasets\n",
    "\n",
    "# Additional optimizer for tuning the hyperparameters\n",
    "# src: https://optuna.org\n",
    "import optuna\n",
    "\n",
    "# used later for testing resnet\n",
    "import torchvision.models as models\n",
    "\n",
    "# used for storing the current best params set\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6d6faa",
   "metadata": {},
   "source": [
    "#### For Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a14f2476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x113e185d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_seed = 11\n",
    "torch.manual_seed(torch_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a41a07",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0586af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = r'./data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef6540c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = datasets.MNIST(root=data_folder, train=True, download = True, transform=None)\n",
    "test_raw =  datasets.MNIST(root=data_folder, train=False,download = True, transform=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe0edec",
   "metadata": {},
   "source": [
    "## Now use the non-transformed data, to visualize those\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7c0918",
   "metadata": {},
   "source": [
    "#### Identifying the shapes of our data sets; expecting: (60k, 28, 28) and (10k, 28, 28), for train and test, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85241ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: torch.Size([60000, 28, 28]) ; \n",
      "test  shape: torch.Size([10000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(f'train shape: {train_raw.data.shape} ; \\ntest  shape: {test_raw.data.shape}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90eb70a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subplot_image( axis_ref, data_structure, lbl_id):\n",
    "    axis_ref.imshow(data_structure.data[lbl_id,:,:].numpy(), cmap='gray')\n",
    "    axis_ref.axis('off')\n",
    "    axis_ref.title.set_text(f\"Label: {data_structure.targets[lbl_id]}\")\n",
    "    pass # only side effects (maybe should return the axis?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d060f6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_panel_of_consecutive_ex_images(init_idx, panel_dims = (3,5) , input_data = train_raw):\n",
    "    fig , ax = plt.subplots(*panel_dims)\n",
    "    X_plt_indx, Y_plt_indx = np.meshgrid(np.arange(panel_dims[0] ) , \n",
    "                                                   np.arange(panel_dims[1]))\n",
    "    sequential_indexed_couple = zip(X_plt_indx.flatten(), Y_plt_indx.flatten() )\n",
    "    [create_subplot_image(ax[plot_tuple_idx[0], plot_tuple_idx[1] ],\n",
    "                          input_data, \n",
    "                          init_idx + seq_idx) for seq_idx, plot_tuple_idx in enumerate(sequential_indexed_couple)]\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87ce7c2",
   "metadata": {},
   "source": [
    "### Example of visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28ada8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 15 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_idx = 35\n",
    "panel_dimension = (3,5)\n",
    "create_panel_of_consecutive_ex_images(start_idx, panel_dims = panel_dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29f89ca",
   "metadata": {},
   "source": [
    "## Create the appropriate transformation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "866e6098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max data value: 255\n",
      "mean: 0.1307; std: 0.3081\n"
     ]
    }
   ],
   "source": [
    "# values inspired by this discussion \n",
    "# [1] https://stackoverflow.com/questions/63746182/correct-way-of-normalizing-and-scaling-the-mnist-dataset\n",
    "\n",
    "# to check my reasoning check the values\n",
    "max_data_value  = train_raw.data.max() # should be 255\n",
    "print(f'Max data value: {max_data_value:3.0f}')\n",
    "\n",
    "img_mean = torch.mean(train_raw.data, dtype=torch.float32)/max_data_value # mean of inputs,\n",
    "# when data are scaled between 0 and 1 (from ToTensor)\n",
    "# torch.Tensor.std(train_raw.data, dtype = torch.float32) this won't work: convertingo to numpy will do the trick\n",
    "\n",
    "img_std = train_raw.data.to_dense().numpy().std()/max_data_value\n",
    "\n",
    "print(f'mean: {img_mean.numpy():.4f}; std: {img_std:.4f}') # expected 0.1307 and 0.3081, respectively, \n",
    "# according to [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42f605af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation pipeline\n",
    "transform_pipeline = transforms.Compose([transforms.ToTensor(), \n",
    "                                transforms.Normalize((img_mean,), (img_std,))\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce8f09a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformed data (to be used by the network)\n",
    "\n",
    "train_data = datasets.MNIST(root=data_folder, train=True,  download = False, transform=transform_pipeline )\n",
    "test_data =  datasets.MNIST(root=data_folder, train=False, download = False, transform=transform_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f6b8fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, img_rows, img_cols = (train_raw.data.numpy().shape)\n",
    "network_input_dim = img_rows * img_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8681c24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions to create data loader (and deal with batches)\n",
    "\n",
    "def get_data_loaded_in_batches(current_data, batch_size, shuffle = True):\n",
    "    return DataLoader(current_data, batch_size = batch_size, shuffle = shuffle)\n",
    "\n",
    "def get_train_and_test_data_w_batch_size(batch_size, train_data = train_data, test_data = test_data ):\n",
    "    return get_data_loaded_in_batches(train_data, batch_size, shuffle=True), \\\n",
    "           get_data_loaded_in_batches(test_data, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ce8354",
   "metadata": {},
   "source": [
    "### Definition of the Neural Network (Non Convolutional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "630d3883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation inspired by the lectures\n",
    "# and by https://github.com/optuna/optuna-examples/blob/main/pytorch/pytorch_simple.py\n",
    "\n",
    "class MNIST_MLP(nn.Module):\n",
    "    def __init__(self , n_nodes, n_classes = 10):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_classes = n_classes\n",
    "        self.activation = F.relu # for now we stick with ReLU\n",
    "        self.output = F.log_softmax # multiple category\n",
    "        self.fc1 = nn.Linear(network_input_dim, n_nodes[0])\n",
    "        self.fc2 = nn.Linear(n_nodes[0], n_nodes[1])\n",
    "        self.fc3 = nn.Linear(n_nodes[1], n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.output(self.fc3(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d7802ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_device(model):\n",
    "    #adapted from: https://stackoverflow.com/questions/58926054/how-to-get-the-device-type-of-a-pytorch-module-conveniently\n",
    "    return next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ae0705f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_num_of_correctly_predicted_samples(predicted, labels):\n",
    "    predicted_labels = torch.argmax(predicted.detach(),1) # possibly detach is not necessary here. Please clarify\n",
    "    return torch.count_nonzero(torch.eq(predicted_labels, labels))\n",
    "\n",
    "def evaluation_step(loss, _ ):\n",
    "    return loss\n",
    "\n",
    "def training_step(loss, optimizer):\n",
    "    # init gradient\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # compute gradient\n",
    "    loss.backward()\n",
    "    \n",
    "    # update the model's weights\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "def batch_process(inputs, labels, optimizer, model, processing_fcn, device, criterion = F.cross_entropy):\n",
    "\n",
    "    # estimate model's prediction\n",
    "    output = model(inputs)\n",
    "\n",
    "    # compute loss\n",
    "    loss = criterion(output, labels)\n",
    "    \n",
    "    # do nothing or train, depending on the processing function\n",
    "    loss = processing_fcn(loss, optimizer)\n",
    "    \n",
    "    # get the number of rightly predicted items\n",
    "    currectly_predicted_samples = get_num_of_correctly_predicted_samples(output, labels)\n",
    "    \n",
    "    return loss, currectly_predicted_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a3ee8c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_data_from_loader_n_get_metrics(data_loader, optimizer, model, processing_fcn,\n",
    "                                               device = None, \n",
    "                                               criterion = F.cross_entropy):\n",
    "    \n",
    "    if not device:\n",
    "        device = get_model_device(model)\n",
    "    \n",
    "    running_loss = 0.0 \n",
    "    train_correct = 0 # init number of correctly classified items\n",
    "    \n",
    "    for index, data in enumerate(data_loader):\n",
    "        \n",
    "        inputs, labels = data\n",
    "        \n",
    "        # dump data to device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        current_loss, currectly_classified_items = batch_process(inputs, labels, optimizer, model, processing_fcn,  device, criterion) # batch_process\n",
    "        running_loss += current_loss.item()\n",
    "        train_correct += currectly_classified_items\n",
    "    \n",
    "    return running_loss, train_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "10e10f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net_on_data(data_loader, optimizer, model,\n",
    "                      device,\n",
    "                      criterion = F.cross_entropy):\n",
    "    model.train()\n",
    "    return process_all_data_from_loader_n_get_metrics(data_loader, optimizer, model, training_step, device, criterion)\n",
    "\n",
    "\n",
    "def eval_net_on_data(data_loader, model,\n",
    "                     device,\n",
    "                     criterion= F.cross_entropy):\n",
    "    model.eval()\n",
    "    return process_all_data_from_loader_n_get_metrics(data_loader, None, model, evaluation_step, device, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "503c16c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerformanceImprover():\n",
    "    def __init__(self , max_count = 5, window = 2, loss_threshold = 1.0e-2, acc_threshold = 1.0e-2):\n",
    "        self.best_val_loss_mean = np.infty\n",
    "        self.best_val_acc_mean = 0.0\n",
    "        self.counter = 0\n",
    "        self.max_count = max_count\n",
    "        self.loss_threshold = loss_threshold\n",
    "        self.acc_threshold = acc_threshold\n",
    "        self.window = window\n",
    "        \n",
    "    def is_improving(self, val_loss, val_accuracy):\n",
    "        \n",
    "        def get_mean_of_last_n_elements(list_of_values, num_of_elements):\n",
    "            return np.mean(list_of_values[-num_of_elements:]) # handles automatically list shorter than num_of_elements\n",
    "        \n",
    "        if not val_loss:\n",
    "            return True\n",
    "        \n",
    "        self.counter += 1 \n",
    "        \n",
    "        current_val_loss_mean = get_mean_of_last_n_elements(val_loss, self.window)\n",
    "        current_val_acc_mean = get_mean_of_last_n_elements(val_accuracy , self.window)\n",
    "        \n",
    "        loss_has_improved = current_val_loss_mean < (self.best_val_loss_mean - self.loss_threshold)\n",
    "        acc_has_improved = current_val_acc_mean  > (self.best_val_acc_mean + self.acc_threshold)\n",
    "      \n",
    "        if (loss_has_improved or acc_has_improved):\n",
    "            \n",
    "            self.counter = 0 # reset counter\n",
    "            \n",
    "            self.best_val_loss_mean = np.min([current_val_loss_mean, self.best_val_loss_mean])\n",
    "            self.best_val_acc_mean = np.max([current_val_acc_mean, self.best_val_acc_mean])     \n",
    "            return True\n",
    "        \n",
    "        elif (self.counter > self.max_count):\n",
    "            return False\n",
    "        \n",
    "        else:\n",
    "            return True                               \n",
    "\n",
    "class TrainingStopper():\n",
    "    def __init__(self, max_epochs = 100 , hist_horizon = 20, is_improving = PerformanceImprover().is_improving):\n",
    "        self.max_epochs = max_epochs\n",
    "        self.hist_horizon = hist_horizon\n",
    "        self.current_epoch = 0\n",
    "        self.is_improving = is_improving\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f\"\"\"Class Parameters:\\n\n",
    "                   Max Epochs: {self.max_epochs} \n",
    "                   History Horizon: {self.hist_horizon}\n",
    "                   Accuracy Threshold:{self.accuracy_threshold}\n",
    "                   Current Epoch:{self.current_epoch}\"\"\"\n",
    "        \n",
    "    def keep_training(self, val_loss, val_accuracy):  \n",
    "        if ( self.current_epoch >= self.max_epochs): # max epochs reached: stop training\n",
    "            print('Max Epochs reached')\n",
    "            return False\n",
    "        \n",
    "        self.current_epoch += 1\n",
    "        print(f\"EPOCH: {self.current_epoch}\")\n",
    "        \n",
    "        return self.is_improving(val_loss, val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4a975218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network_classification(net, train_loader, test_loader, optimizer, stopping_algorithm = TrainingStopper(), \n",
    "                                 criterion = F.cross_entropy):\n",
    "    \n",
    "    device = get_model_device(net)\n",
    "    train_loss_history, training_acc_hist  = list(), list()\n",
    "    val_loss_history, val_acc_hist = list(), list()\n",
    "    \n",
    "    num_train_samples = len(train_loader.dataset)\n",
    "    num_val_samples = len(test_loader.dataset)\n",
    "    \n",
    "    best_test_accuracy = 0.0\n",
    "    best_net_weights = net.state_dict()\n",
    "    \n",
    "    while stopping_algorithm.keep_training(val_loss_history, val_acc_hist):\n",
    "        \n",
    "        # training step\n",
    "        training_loss, num_corrected_samples_train = \\\n",
    "            train_net_on_data(train_loader, optimizer, net, device, criterion)\n",
    "        training_accuracy = num_corrected_samples_train / num_train_samples * 100.0\n",
    "        \n",
    "        train_loss_history.append(training_loss)\n",
    "        training_acc_hist.append(training_accuracy)\n",
    "        \n",
    "        # evaluation step\n",
    "        eval_loss, num_corrected_samples_test = eval_net_on_data(test_loader, net, device, criterion)\n",
    "        testing_accuracy = num_corrected_samples_test / num_val_samples * 100.0\n",
    "        \n",
    "        val_loss_history.append(eval_loss)\n",
    "        val_acc_hist.append(testing_accuracy)\n",
    "        \n",
    "        print(f'Training Accuracy: {training_accuracy:.4f}; Validation Accuracy: {testing_accuracy:.4f}')\n",
    "                \n",
    "        if testing_accuracy > best_test_accuracy:\n",
    "            \n",
    "            best_test_accuracy = testing_accuracy\n",
    "            \n",
    "            # Create a deep copy of the model's parameters, otherwise dict is stored by reference\n",
    "            best_net_weights = copy.deepcopy(net.state_dict())\n",
    "                \n",
    "#     # load the best net on test data\n",
    "    net.load_state_dict(best_net_weights)\n",
    "    \n",
    "    return net, (train_loss_history, training_acc_hist), (val_loss_history, val_acc_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f608b6e",
   "metadata": {},
   "source": [
    "#### Hyperparameters not optimized (fixed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "27f3f371",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "HIDDEN_NODES = (64,64)\n",
    "LEARNING_RATE = lr=0.00011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f116c3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNIST_MLP(HIDDEN_NODES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5ca9cfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# current execution\n",
    "train_data_loaded , test_data_loaded = get_train_and_test_data_w_batch_size(BATCH_SIZE )\n",
    "\n",
    "# model creation (use CPU: faster for small networks)\n",
    "model = MNIST_MLP(HIDDEN_NODES)\n",
    "\n",
    "# create optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# algo_stopper = TrainingStopper(max_epochs=2)\n",
    "# print(algo_stopper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0d71fc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1\n",
      "Training Accuracy: 81.9517; Validation Accuracy: 90.8400\n",
      "EPOCH: 2\n",
      "Training Accuracy: 91.2900; Validation Accuracy: 92.5200\n",
      "EPOCH: 3\n",
      "Training Accuracy: 92.6050; Validation Accuracy: 93.3900\n",
      "EPOCH: 4\n",
      "Training Accuracy: 93.5850; Validation Accuracy: 94.0900\n",
      "EPOCH: 5\n",
      "Training Accuracy: 94.3500; Validation Accuracy: 94.5800\n",
      "EPOCH: 6\n",
      "Training Accuracy: 94.9200; Validation Accuracy: 95.0900\n",
      "EPOCH: 7\n",
      "Training Accuracy: 95.4583; Validation Accuracy: 95.2900\n",
      "EPOCH: 8\n",
      "Training Accuracy: 95.8633; Validation Accuracy: 95.4200\n",
      "EPOCH: 9\n",
      "Training Accuracy: 96.1800; Validation Accuracy: 95.8200\n",
      "EPOCH: 10\n",
      "Training Accuracy: 96.4450; Validation Accuracy: 96.1600\n",
      "EPOCH: 11\n",
      "Training Accuracy: 96.7800; Validation Accuracy: 96.1700\n",
      "EPOCH: 12\n",
      "Training Accuracy: 96.9767; Validation Accuracy: 96.3700\n",
      "EPOCH: 13\n",
      "Training Accuracy: 97.1467; Validation Accuracy: 96.2300\n",
      "EPOCH: 14\n",
      "Training Accuracy: 97.3183; Validation Accuracy: 96.4100\n",
      "EPOCH: 15\n",
      "Training Accuracy: 97.4867; Validation Accuracy: 96.7100\n",
      "EPOCH: 16\n",
      "Training Accuracy: 97.6167; Validation Accuracy: 96.6900\n",
      "EPOCH: 17\n",
      "Training Accuracy: 97.7300; Validation Accuracy: 96.9600\n",
      "EPOCH: 18\n",
      "Training Accuracy: 97.8950; Validation Accuracy: 96.8900\n",
      "EPOCH: 19\n",
      "Training Accuracy: 98.0267; Validation Accuracy: 96.9700\n",
      "EPOCH: 20\n",
      "Training Accuracy: 98.1167; Validation Accuracy: 97.0700\n",
      "EPOCH: 21\n",
      "Training Accuracy: 98.2617; Validation Accuracy: 97.0600\n",
      "EPOCH: 22\n",
      "Training Accuracy: 98.2983; Validation Accuracy: 97.0900\n",
      "EPOCH: 23\n",
      "Training Accuracy: 98.4550; Validation Accuracy: 97.1600\n",
      "EPOCH: 24\n",
      "Training Accuracy: 98.5100; Validation Accuracy: 97.2900\n",
      "EPOCH: 25\n",
      "Training Accuracy: 98.5833; Validation Accuracy: 97.3100\n",
      "EPOCH: 26\n",
      "Training Accuracy: 98.6750; Validation Accuracy: 97.3200\n",
      "EPOCH: 27\n",
      "Training Accuracy: 98.7100; Validation Accuracy: 97.2200\n",
      "EPOCH: 28\n",
      "Training Accuracy: 98.8083; Validation Accuracy: 97.4100\n",
      "EPOCH: 29\n",
      "Training Accuracy: 98.8783; Validation Accuracy: 97.4500\n",
      "EPOCH: 30\n",
      "Training Accuracy: 98.9400; Validation Accuracy: 97.4700\n",
      "EPOCH: 31\n",
      "Training Accuracy: 99.0217; Validation Accuracy: 97.2800\n",
      "EPOCH: 32\n",
      "Training Accuracy: 99.0467; Validation Accuracy: 97.4300\n",
      "EPOCH: 33\n",
      "Training Accuracy: 99.1450; Validation Accuracy: 97.5300\n",
      "EPOCH: 34\n",
      "Training Accuracy: 99.1700; Validation Accuracy: 97.5700\n",
      "EPOCH: 35\n",
      "Training Accuracy: 99.2217; Validation Accuracy: 97.5800\n",
      "EPOCH: 36\n",
      "Training Accuracy: 99.2767; Validation Accuracy: 97.4800\n",
      "EPOCH: 37\n",
      "Training Accuracy: 99.3117; Validation Accuracy: 97.4900\n",
      "EPOCH: 38\n",
      "Training Accuracy: 99.3500; Validation Accuracy: 97.3900\n",
      "EPOCH: 39\n",
      "Training Accuracy: 99.3783; Validation Accuracy: 97.5500\n",
      "EPOCH: 40\n",
      "Training Accuracy: 99.4417; Validation Accuracy: 97.6600\n",
      "EPOCH: 41\n",
      "Training Accuracy: 99.4967; Validation Accuracy: 97.6200\n",
      "EPOCH: 42\n",
      "Training Accuracy: 99.4933; Validation Accuracy: 97.5600\n",
      "EPOCH: 43\n",
      "Training Accuracy: 99.5733; Validation Accuracy: 97.5800\n",
      "EPOCH: 44\n",
      "Training Accuracy: 99.5950; Validation Accuracy: 97.5200\n",
      "EPOCH: 45\n",
      "Training Accuracy: 99.6183; Validation Accuracy: 97.6300\n",
      "EPOCH: 46\n",
      "Training Accuracy: 99.6517; Validation Accuracy: 97.6600\n",
      "EPOCH: 47\n",
      "Training Accuracy: 99.7100; Validation Accuracy: 97.6000\n",
      "EPOCH: 48\n"
     ]
    }
   ],
   "source": [
    "model, (tr_loss, tr_acc), (val_loss, val_cc)= train_network_classification(model, train_data_loaded, test_data_loaded,optimizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7b57f2",
   "metadata": {},
   "source": [
    "### Optimize hyperparameters with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed05f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspired by https://github.com/optuna/optuna-examples/blob/main/pytorch/pytorch_simple.py\n",
    "\n",
    "def objective(trial):\n",
    "    # Generate the model.\n",
    "    model = define_model(trial).to(DEVICE)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "    # Get the FashionMNIST dataset.\n",
    "    train_loader, valid_loader = get_mnist()\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # Limiting training data for faster epochs.\n",
    "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
    "                break\n",
    "\n",
    "            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "                # Limiting validation data.\n",
    "                if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
    "                    break\n",
    "                data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "                output = model(data)\n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        accuracy = correct / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n",
    "\n",
    "        trial.report(accuracy, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe0a68f",
   "metadata": {},
   "source": [
    "### Get use of HW acceleration, if available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33d4f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_HW_acceleration_if_available():\n",
    "    try:\n",
    "        if torch.backends.mps.is_available():\n",
    "            return 'mps'\n",
    "    except AttributeError:\n",
    "        pass\n",
    "        \n",
    "    if torch.cuda.is_available():\n",
    "        return 'cuda'\n",
    "    \n",
    "    return 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c72182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abe4cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_HW_acceleration_if_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b05bb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5dec09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29ad3215",
   "metadata": {},
   "source": [
    "### Try with Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1078c4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "# Load a pre-trained ResNet-18 model\n",
    "resnet = (models.resnet18(pretrained=True)).to('mps')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e30de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Modify the first convolutional layer to accept 1 input channel\n",
    "# The original input channels were 3 (RGB), change it to 1\n",
    "resnet.conv1 = (nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)).to('mps')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6305f032",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10  # MNIST has 10 classes (digits 0-9)\n",
    "resnet.fc = (nn.Linear(resnet.fc.in_features, num_classes)).to('mps')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d8b280",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_stopper = TrainingStopper(max_epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3929a3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_network_classification(resnet, train_data_loaded, test_data_loaded, algo_stopper, optim.Adam(resnet.parameters(), lr= 0.00045), criterion=F.cross_entropy, device='mps')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
