{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb83a7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "from MNIST_solver import eval_net_on_data\n",
    "from  MNIST_solver import create_panel_of_consecutive_ex_images, get_max_n_normalized_mean_n_std\n",
    "from MNIST_solver import get_train_and_test_data_w_batch_size, MNIST_MLP, eval_net_on_data\n",
    "from MNIST_solver import PerformanceImprover, TrainingStopper, train_network_classification\n",
    "from MNIST_solver import define_objective_fcn_with_params, get_HW_acceleration_if_available\n",
    "\n",
    "from MNIST_solver import get_model_device, train_net_on_data\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "\n",
    "device = get_HW_acceleration_if_available()\n",
    "print(f\"Device used: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "871f49d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_seed = 11\n",
    "torch.manual_seed(torch_seed)\n",
    "data_folder = r'./data'\n",
    "train_raw = datasets.MNIST(root=data_folder, train=True, download = True, transform=None)\n",
    "test_raw =  datasets.MNIST(root=data_folder, train=False,download = True, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3aca1e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max data value: 255\n",
      "mean: 0.1307; std: 0.3081\n"
     ]
    }
   ],
   "source": [
    "max_data_value, img_mean, img_std = get_max_n_normalized_mean_n_std(train_raw)\n",
    "print(f'Max data value: {max_data_value:3.0f}')\n",
    "\n",
    "\n",
    "print(f'mean: {img_mean.numpy():.4f}; std: {img_std:.4f}') # expected 0.1307 and 0.3081, respectively, \n",
    "# according to [1]\n",
    "# Define transformation pipeline\n",
    "transform_pipeline = transforms.Compose([transforms.ToTensor(), \n",
    "                                transforms.Normalize((img_mean,), (img_std,))\n",
    "                               ])\n",
    "\n",
    "# Transformed data (to be used by the network)\n",
    "train_data = datasets.MNIST(root=data_folder, train=True,  download = False, transform=transform_pipeline )\n",
    "test_data =  datasets.MNIST(root=data_folder, train=False, download = False, transform=transform_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb958de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, img_rows, img_cols = (train_raw.data.numpy().shape)\n",
    "network_input_dim = img_rows * img_cols\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "HIDDEN_NODES = (64,64)\n",
    "LEARNING_RATE = lr=0.00011\n",
    "\n",
    "# current execution\n",
    "train_data_loaded , test_data_loaded = get_train_and_test_data_w_batch_size(BATCH_SIZE , train_data, test_data)\n",
    "\n",
    "# model creation (use CPU: faster for small networks)\n",
    "model = MNIST_MLP(network_input_dim, HIDDEN_NODES)\n",
    "\n",
    "# create optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f65401",
   "metadata": {},
   "source": [
    "### Try with Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "482b84b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this code has been adapted from the suggestions made by chatGPT version 3.5, searching for transfer learning\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "class ResNetForMNIST(nn.Module):\n",
    "    def __init__(self, resnet):\n",
    "        super(ResNetForMNIST, self).__init__()\n",
    "        \n",
    "        self.resnet =  models.resnet18(weights='ResNet18_Weights.DEFAULT')\n",
    "        resnet.fc = nn.Linear(resnet.fc.in_features, num_classes)\n",
    "        \n",
    "        self.freeze_all_layers_but_lastone()\n",
    "        \n",
    "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)  # Apply softmax along the dimension of classes\n",
    "        \n",
    "        \n",
    "        \n",
    "    def freeze_all_layers_but_lastone(self):\n",
    "        \n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "            resnet.fc.requires_grad = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.resnet(x)\n",
    "        probabilities = self.softmax(logits)\n",
    "        \n",
    "        # Use torch.max to get the most likely class\n",
    "        max_values, predicted_class = torch.max(probabilities, dim=1)\n",
    "        return logits, probabilities, predicted_class\n",
    "\n",
    "# Load the pre-trained ResNet-18 model\n",
    "resnet =\n",
    "\n",
    "# Modify the final classification layer to output raw scores (logits)\n",
    "num_classes = 10\n",
    "\n",
    "\n",
    "# Create the modified model\n",
    "model = ResNetForMNIST(resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7fb27fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model_device(resnet)\n",
    "train_loss_history, training_acc_hist = list(), list()\n",
    "val_loss_history, val_acc_hist = list(), list()\n",
    "num_train_samples = len(train_data_loaded.dataset)\n",
    "num_val_samples = len(test_data_loaded.dataset)\n",
    "best_test_accuracy = 0.0\n",
    "best_net_weights = resnet.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e2bb884",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(resnet.parameters(), lr= 0.00045)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4c1b2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device\n",
    "import torch.nn.functional as F\n",
    "criterion=F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc50d042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_third_output(x):\n",
    "    return x[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b911649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNIST_MLP(\n",
       "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32b2bef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_to_output_fcn = get_third_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98b8afb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_data_from_loader_n_get_metrics(data_loader, optimizer, model, processing_fcn,\n",
    "                                               criterion=F.cross_entropy,\n",
    "                                               net_to_output_fcn = lambda x:x):\n",
    "    device = get_model_device(model)\n",
    "\n",
    "    running_loss = 0.0\n",
    "    train_correct = 0  # init number of correctly classified items\n",
    "\n",
    "    for data in data_loader:\n",
    "        inputs, labels = data\n",
    "\n",
    "        # dump data to device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        current_loss, correctly_classified_items = batch_process(inputs, labels, optimizer, model,\n",
    "                                                                 processing_fcn,\n",
    "                                                                 criterion,\n",
    "                                                                 net_to_output_fcn)  # batch_process\n",
    "        running_loss += current_loss.item()\n",
    "        train_correct += correctly_classified_items\n",
    "\n",
    "    return running_loss, train_correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9852eac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [data for data in train_data_loaded ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "50f0411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test = X[0][0]\n",
    "label_test = X[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7cd618ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test, label_test = input_test.to(device), label_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "10c30fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.2670, -2.1981, -2.2263, -2.3381, -2.3836, -2.2411, -2.3347, -2.4210,\n",
       "         -2.3858, -2.2567],\n",
       "        [-2.2945, -2.3270, -2.3775, -2.1820, -2.2927, -2.2525, -2.3156, -2.3626,\n",
       "         -2.4053, -2.2373],\n",
       "        [-2.3361, -2.2488, -2.2427, -2.2083, -2.3087, -2.2281, -2.4018, -2.3801,\n",
       "         -2.4131, -2.2832],\n",
       "        [-2.2925, -2.2266, -2.2810, -2.2683, -2.3880, -2.2299, -2.3820, -2.3735,\n",
       "         -2.3916, -2.2158],\n",
       "        [-2.3065, -2.2183, -2.3992, -2.2082, -2.2588, -2.2558, -2.3172, -2.4017,\n",
       "         -2.3982, -2.2863],\n",
       "        [-2.2090, -2.2905, -2.2793, -2.2633, -2.3507, -2.2668, -2.2557, -2.4023,\n",
       "         -2.4131, -2.3146],\n",
       "        [-2.2777, -2.1889, -2.3724, -2.1299, -2.3002, -2.2013, -2.3832, -2.4798,\n",
       "         -2.5497, -2.2226],\n",
       "        [-2.2821, -2.2206, -2.2665, -2.1827, -2.2915, -2.2159, -2.4140, -2.3624,\n",
       "         -2.4961, -2.3355],\n",
       "        [-2.2494, -2.2041, -2.3290, -2.1570, -2.3675, -2.3063, -2.4111, -2.4131,\n",
       "         -2.4657, -2.1754],\n",
       "        [-2.3690, -2.3962, -2.2056, -2.1584, -2.3694, -2.2002, -2.3315, -2.4059,\n",
       "         -2.4435, -2.1967],\n",
       "        [-2.2864, -2.2921, -2.3025, -2.1989, -2.2949, -2.2977, -2.3879, -2.3957,\n",
       "         -2.3397, -2.2459],\n",
       "        [-2.4409, -2.4121, -2.2165, -2.1334, -2.3776, -2.2473, -2.3706, -2.3530,\n",
       "         -2.3763, -2.1542],\n",
       "        [-2.2326, -2.2683, -2.2976, -2.2149, -2.3499, -2.2913, -2.3745, -2.3690,\n",
       "         -2.4202, -2.2298],\n",
       "        [-2.3385, -2.2012, -2.3758, -2.1439, -2.2628, -2.1404, -2.4149, -2.4802,\n",
       "         -2.5425, -2.2140],\n",
       "        [-2.3075, -2.3010, -2.2221, -2.2581, -2.3962, -2.1812, -2.3544, -2.5012,\n",
       "         -2.4155, -2.1440],\n",
       "        [-2.3461, -2.1863, -2.2940, -2.1319, -2.3627, -2.3100, -2.3814, -2.3769,\n",
       "         -2.4049, -2.2683],\n",
       "        [-2.1943, -2.1524, -2.2699, -2.2022, -2.3891, -2.2653, -2.4517, -2.3848,\n",
       "         -2.5101, -2.2687],\n",
       "        [-2.2189, -2.2242, -2.1951, -2.2202, -2.3821, -2.1725, -2.3901, -2.4064,\n",
       "         -2.5334, -2.3457],\n",
       "        [-2.2784, -2.2208, -2.3134, -2.1888, -2.3078, -2.2597, -2.4511, -2.3425,\n",
       "         -2.4953, -2.2124],\n",
       "        [-2.2732, -2.2727, -2.3737, -2.1986, -2.3135, -2.1736, -2.3938, -2.3705,\n",
       "         -2.4783, -2.2201],\n",
       "        [-2.2616, -2.2428, -2.3870, -2.1836, -2.2506, -2.1937, -2.3818, -2.3574,\n",
       "         -2.5320, -2.2854],\n",
       "        [-2.3268, -2.3041, -2.4087, -2.1964, -2.2696, -2.2314, -2.3367, -2.3709,\n",
       "         -2.4350, -2.1801],\n",
       "        [-2.2591, -2.2719, -2.2910, -2.2354, -2.3414, -2.2350, -2.3474, -2.4136,\n",
       "         -2.4060, -2.2456],\n",
       "        [-2.2300, -2.2300, -2.3124, -2.1402, -2.3211, -2.2811, -2.4325, -2.4300,\n",
       "         -2.4509, -2.2455],\n",
       "        [-2.2867, -2.2604, -2.2927, -2.1911, -2.2112, -2.1980, -2.4393, -2.3646,\n",
       "         -2.5438, -2.2933],\n",
       "        [-2.3265, -2.1729, -2.3784, -2.2218, -2.3012, -2.3703, -2.3196, -2.3103,\n",
       "         -2.4396, -2.2158],\n",
       "        [-2.3013, -2.3076, -2.3588, -2.2499, -2.3032, -2.2383, -2.2775, -2.3648,\n",
       "         -2.3561, -2.2775],\n",
       "        [-2.3182, -2.1419, -2.3624, -2.1924, -2.2809, -2.2082, -2.4170, -2.4229,\n",
       "         -2.4729, -2.2636],\n",
       "        [-2.3674, -2.3086, -2.1957, -2.2064, -2.3903, -2.1860, -2.4043, -2.3973,\n",
       "         -2.4127, -2.2013],\n",
       "        [-2.3425, -2.1951, -2.2758, -2.2869, -2.3787, -2.2503, -2.3650, -2.3689,\n",
       "         -2.3027, -2.2759],\n",
       "        [-2.2952, -2.2330, -2.2716, -2.2709, -2.3252, -2.2430, -2.3698, -2.3416,\n",
       "         -2.4082, -2.2817],\n",
       "        [-2.2018, -2.1585, -2.3088, -2.1502, -2.3604, -2.2786, -2.4601, -2.4668,\n",
       "         -2.5346, -2.1921],\n",
       "        [-2.2359, -2.2325, -2.1501, -2.2566, -2.4277, -2.2354, -2.4034, -2.4186,\n",
       "         -2.4436, -2.2713],\n",
       "        [-2.3540, -2.1853, -2.4479, -2.1373, -2.1851, -2.2430, -2.3381, -2.3414,\n",
       "         -2.5696, -2.3001],\n",
       "        [-2.2770, -2.2644, -2.2174, -2.2699, -2.3686, -2.3258, -2.3106, -2.4454,\n",
       "         -2.3001, -2.2648],\n",
       "        [-2.2608, -2.2695, -2.3327, -2.2547, -2.3263, -2.2598, -2.3200, -2.3881,\n",
       "         -2.3722, -2.2534],\n",
       "        [-2.2575, -2.3411, -2.3066, -2.1884, -2.3073, -2.2704, -2.4008, -2.3537,\n",
       "         -2.4064, -2.2175],\n",
       "        [-2.2337, -2.1870, -2.2842, -2.3175, -2.3953, -2.3246, -2.2921, -2.3535,\n",
       "         -2.4260, -2.2371],\n",
       "        [-2.2393, -2.1834, -2.2598, -2.2092, -2.4116, -2.2317, -2.4534, -2.4704,\n",
       "         -2.4591, -2.1754],\n",
       "        [-2.2396, -2.2645, -2.3267, -2.2279, -2.3143, -2.2367, -2.3337, -2.4128,\n",
       "         -2.4213, -2.2702],\n",
       "        [-2.2456, -2.2863, -2.3454, -2.2006, -2.3147, -2.2057, -2.3473, -2.4163,\n",
       "         -2.4151, -2.2755],\n",
       "        [-2.4209, -2.3952, -2.1297, -2.1430, -2.4749, -2.2247, -2.4534, -2.3795,\n",
       "         -2.3940, -2.1062],\n",
       "        [-2.4240, -2.3168, -2.1925, -2.1902, -2.3809, -2.1510, -2.5289, -2.3437,\n",
       "         -2.4319, -2.1465],\n",
       "        [-2.2403, -2.2089, -2.3001, -2.2869, -2.3496, -2.3010, -2.3445, -2.3767,\n",
       "         -2.4147, -2.2238],\n",
       "        [-2.2806, -2.3080, -2.3062, -2.2276, -2.3077, -2.2290, -2.3521, -2.3755,\n",
       "         -2.3991, -2.2554],\n",
       "        [-2.3086, -2.2606, -2.4046, -2.1954, -2.2874, -2.2046, -2.3492, -2.3791,\n",
       "         -2.4441, -2.2257],\n",
       "        [-2.2837, -2.2769, -2.2899, -2.1586, -2.3369, -2.2972, -2.3493, -2.3173,\n",
       "         -2.5081, -2.2426],\n",
       "        [-2.2603, -2.2493, -2.3656, -2.2472, -2.3528, -2.2844, -2.3079, -2.4066,\n",
       "         -2.4389, -2.1470],\n",
       "        [-2.2461, -2.2812, -2.3321, -2.2533, -2.3283, -2.2729, -2.2980, -2.3854,\n",
       "         -2.3890, -2.2522],\n",
       "        [-2.4606, -2.2071, -2.2591, -2.2625, -2.3920, -2.1339, -2.4040, -2.4061,\n",
       "         -2.3550, -2.1998],\n",
       "        [-2.2601, -2.2544, -2.2984, -2.2216, -2.4249, -2.3535, -2.3213, -2.3666,\n",
       "         -2.3874, -2.1670],\n",
       "        [-2.2720, -2.2426, -2.2981, -2.3164, -2.4006, -2.1882, -2.3205, -2.3582,\n",
       "         -2.4160, -2.2370],\n",
       "        [-2.2803, -2.3074, -2.3384, -2.2153, -2.3058, -2.2155, -2.3439, -2.3862,\n",
       "         -2.3748, -2.2740],\n",
       "        [-2.2816, -2.2773, -2.2096, -2.2386, -2.3153, -2.1521, -2.4836, -2.4082,\n",
       "         -2.4202, -2.2861],\n",
       "        [-2.2753, -2.2369, -2.2860, -2.2320, -2.3103, -2.1973, -2.3761, -2.3303,\n",
       "         -2.4955, -2.3178],\n",
       "        [-2.1418, -2.2714, -2.2452, -2.2127, -2.3694, -2.2345, -2.3880, -2.3923,\n",
       "         -2.5237, -2.3015],\n",
       "        [-2.2536, -2.2544, -2.2915, -2.2349, -2.3211, -2.2383, -2.3728, -2.4524,\n",
       "         -2.3492, -2.2791],\n",
       "        [-2.2870, -2.2269, -2.2516, -2.2255, -2.3852, -2.2079, -2.4360, -2.3838,\n",
       "         -2.4962, -2.1784],\n",
       "        [-2.3233, -2.1780, -2.3522, -2.1853, -2.3404, -2.2960, -2.3278, -2.3989,\n",
       "         -2.3927, -2.2583],\n",
       "        [-2.1901, -2.1096, -2.2808, -2.3031, -2.3321, -2.3315, -2.3254, -2.4127,\n",
       "         -2.5292, -2.2695],\n",
       "        [-2.2489, -2.3399, -2.3880, -2.2526, -2.2951, -2.2569, -2.2898, -2.3915,\n",
       "         -2.3384, -2.2395],\n",
       "        [-2.2044, -2.1645, -2.2775, -2.3391, -2.3782, -2.3518, -2.3111, -2.3899,\n",
       "         -2.3796, -2.2574],\n",
       "        [-2.2159, -2.2905, -2.2714, -2.2390, -2.3784, -2.2342, -2.3106, -2.4355,\n",
       "         -2.4402, -2.2413],\n",
       "        [-2.2794, -2.3101, -2.2253, -2.2062, -2.3210, -2.2176, -2.4407, -2.3560,\n",
       "         -2.4373, -2.2643]], device='mps:0', grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model(input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b0054bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96d55ea3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch (got input: [10], target: [64])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m training_loss, num_corrected_samples_train \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m----> 2\u001b[0m             \u001b[43mtrain_net_on_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_loaded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_third_output\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/Python/Udacity-DeepLearning/CourseOne/MNIST_solver.py:164\u001b[0m, in \u001b[0;36mtrain_net_on_data\u001b[0;34m(data_loader, optimizer, model, criterion, net_to_output_fcn)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_net_on_data\u001b[39m(data_loader, optimizer, model,\n\u001b[1;32m    161\u001b[0m                       criterion\u001b[38;5;241m=\u001b[39mF\u001b[38;5;241m.\u001b[39mcross_entropy,\n\u001b[1;32m    162\u001b[0m                       net_to_output_fcn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x:x):\n\u001b[1;32m    163\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprocess_all_data_from_loader_n_get_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet_to_output_fcn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/Python/Udacity-DeepLearning/CourseOne/MNIST_solver.py:150\u001b[0m, in \u001b[0;36mprocess_all_data_from_loader_n_get_metrics\u001b[0;34m(data_loader, optimizer, model, processing_fcn, criterion, net_to_output_fcn)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# dump data to device\u001b[39;00m\n\u001b[1;32m    148\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 150\u001b[0m current_loss, correctly_classified_items \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43mprocessing_fcn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43mnet_to_output_fcn\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# batch_process\u001b[39;00m\n\u001b[1;32m    154\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m current_loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    155\u001b[0m train_correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m correctly_classified_items\n",
      "File \u001b[0;32m~/Code/Python/Udacity-DeepLearning/CourseOne/MNIST_solver.py:126\u001b[0m, in \u001b[0;36mbatch_process\u001b[0;34m(inputs, labels, optimizer, model, processing_fcn, criterion, net_to_output_fcn)\u001b[0m\n\u001b[1;32m    123\u001b[0m output \u001b[38;5;241m=\u001b[39m net_to_output_fcn(output_from_net)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# compute loss\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# do nothing or train, depending on the processing function\u001b[39;00m\n\u001b[1;32m    129\u001b[0m loss \u001b[38;5;241m=\u001b[39m processing_fcn(loss, optimizer)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/torch/nn/functional.py:3029\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3028\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3029\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch (got input: [10], target: [64])"
     ]
    }
   ],
   "source": [
    "training_loss, num_corrected_samples_train = \\\n",
    "            train_net_on_data(train_data_loaded, optimizer, resnet, criterion, get_third_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
